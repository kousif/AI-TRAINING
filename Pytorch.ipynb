{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j4wIFDnRakTz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJyLCI8PcPZq"
      },
      "source": [
        "## Init tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NV2jveDIayX-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.7063, 0.6321],\n",
            "        [0.6462, 0.6457],\n",
            "        [0.0727, 0.6894]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(3, 2)\n",
        "print(x)\n",
        "x = torch.zeros(3, 2)\n",
        "print(x)\n",
        "x = torch.rand(3, 2)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BuAQVNaPFN1P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.empty(3, 2)\n",
        "print(x)\n",
        "y = torch.zeros_like(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bWrOMr-hFbwo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.linspace(0, 1, steps=5)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "l_QspfvYEtuB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wKub-KJLcSDJ"
      },
      "source": [
        "## Slicing ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UxSlfSVrbH8h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.size())\n",
        "print(x[:, 1]) \n",
        "print(x[0, :]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AGWkj2utcrz9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "y = x[1, 1]\n",
        "print(y)\n",
        "print(y.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6YvWGrX0cUpf"
      },
      "source": [
        "## Reshaping \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mn1q-Hm7b6hP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "y = x.view(2, 3)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1EbIwPvBF4Lg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6]])\n"
          ]
        }
      ],
      "source": [
        "y = x.view(6,-1) \n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2XxOq0ObdXEC"
      },
      "source": [
        "## STO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Rv4jjqBVdIB2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones([3, 2])\n",
        "y = torch.ones([3, 2])\n",
        "z = x + y\n",
        "print(z)\n",
        "z = x - y\n",
        "print(z)\n",
        "z = x * y\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dVHnXB78dl8s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "z = y.add(x)\n",
        "print(z)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LewBBuz_eL1m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "z = y.add_(x)\n",
        "print(z)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PDuBSdzTc2Bq"
      },
      "source": [
        "## Numpy  PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NlvqO8_1ccML"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "x_np = x.numpy()\n",
        "print(type(x), type(x_np))\n",
        "print(x_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tLhS3Hrmc-M2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.22885007 -0.67411774  0.25298311  1.47519692  0.20738995]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
            "tensor([-0.2289, -0.6741,  0.2530,  1.4752,  0.2074], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "a = np.random.randn(5)\n",
        "print(a)\n",
        "a_pt = torch.from_numpy(a)\n",
        "print(type(a), type(a_pt))\n",
        "print(a_pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kwZhRYVtdp-X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.77114993 0.32588226 1.25298311 2.47519692 1.20738995]\n",
            "tensor([0.7711, 0.3259, 1.2530, 2.4752, 1.2074], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(a_pt) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6z-Mhf2hewcU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 93.8 ms\n",
            "Wall time: 80.7 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = np.random.randn(100,100)\n",
        "  b = np.random.randn(100,100)\n",
        "  c = np.matmul(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aFzIX2qge3x9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 46.9 ms\n",
            "Wall time: 42.5 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = torch.randn([100, 100])\n",
        "  b = torch.randn([100, 100])\n",
        "  c = torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Pdat0Hnm6hGA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 33.8 s\n",
            "Wall time: 35.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XlRx5OKl6kEq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 14.5 s\n",
            "Wall time: 10.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000])\n",
        "  b = torch.randn([10000, 10000])\n",
        "  c = a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "de5YwtfUgMWO"
      },
      "source": [
        "## CUDA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-nI4nYcWgY1B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_3E-PMC1gfKU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x000001C6729D39D0>\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.cuda.device(\u001b[32m0\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shaik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:582\u001b[39m, in \u001b[36mget_device_name\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_name\u001b[39m(device: \u001b[33m\"\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    571\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[32m    572\u001b[39m \n\u001b[32m    573\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    580\u001b[39m \u001b[33;03m        str: the name of the device\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.name\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shaik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:614\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_properties\u001b[39m(device: \u001b[33m\"\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CudaDeviceProperties:\n\u001b[32m    603\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[32m    604\u001b[39m \n\u001b[32m    605\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m \u001b[33;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[32m    615\u001b[39m     device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shaik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
            "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_eZYxVpMgor4"
      },
      "outputs": [],
      "source": [
        "cuda0 = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j1r7y57x9JZU"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m a = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcuda0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m b = torch.ones(\u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, device=cuda0)\n\u001b[32m      3\u001b[39m c = a + b\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shaik\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
            "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "a = torch.ones(3, 2, device=cuda0)\n",
        "b = torch.ones(3, 2, device=cuda0)\n",
        "c = a + b\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "a = torch.ones(3, 2, device='cpu')\n",
        "b = torch.ones(3, 2, device='cpu')\n",
        "c = a + b\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wSt3W1s-_Gc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sVfOAU2EfTXB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 32.9 s\n",
            "Wall time: 33.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  np.add(b, a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G9GLUek5hCfn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 11.9 s\n",
            "Wall time: 8.91 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu.add_(a_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FqSYioGrgyMI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 12.2 s\n",
            "Wall time: 9.56 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000], device='cpu')\n",
        "  b = torch.randn([10000, 10000], device='cpu')\n",
        "  b.add_(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Kjsl8xRFjPtT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 32min 8s\n",
            "Wall time: 3min 33s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  np.matmul(b, a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "avFqbCgXjT3F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 13min 37s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu = torch.randn([10000, 10000])\n",
        "  torch.matmul(a_cpu, b_cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hFfMhN2gjlZJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 13min 26s\n",
            "Wall time: 1min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000], device='cpu')\n",
        "  b = torch.randn([10000, 10000], device='cpu')\n",
        "  torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P_6TU64Gi7jv"
      },
      "source": [
        "## Autodiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "PjySsLMThEX7",
        "outputId": "b1cef456-8281-42b0-8205-d7b988c3c383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "neb3oFWBjAtJ",
        "outputId": "a9e1faf0-841d-41d1-f9c4-e429e1fdd0bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 5\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "5M0pnstAjLa-",
        "outputId": "b9861325-9ec6-41bb-995f-ae54210628c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y*y + 1\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "colab_type": "code",
        "id": "wHHDSmiUkMOw",
        "outputId": "93374258-d506-4eba-c359-13fc160d0123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "t = torch.sum(z)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AXj896azkM_S"
      },
      "outputs": [],
      "source": [
        "t.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "wSYAcNN1lAWS",
        "outputId": "c82aa737-eb40-45f5-ad44-5e28484d5e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "colab_type": "code",
        "id": "ZFCWPPAP6ipv",
        "outputId": "d1d2243a-af30-4317-e303-3eee8058400e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1/(1 + torch.exp(-y))\n",
        "print(r)\n",
        "s = torch.sum(r)\n",
        "s.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "Ts1wsONqlE5h",
        "outputId": "f42bd6a2-0c97-4b44-96d0-3e9eae2b90a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1/(1 + torch.exp(-y))\n",
        "a = torch.ones([3, 2])\n",
        "r.backward(a)\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKhxwdYUpUfj"
      },
      "source": [
        "## Autodiff ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "THNkQLR6mmpO"
      },
      "outputs": [],
      "source": [
        "x = torch.randn([20, 1], requires_grad=True)\n",
        "y = 3*x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-t4_8qgdnjDk"
      },
      "outputs": [],
      "source": [
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "y_hat = w*x + b\n",
        "\n",
        "loss = torch.sum((y_hat - y)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "colab_type": "code",
        "id": "Gvpc37u-o6ob",
        "outputId": "6846154f-587d-4aa3-cad5-4e3be6d08fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(240.5295, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-tnKq6DXo-RB"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "colab_type": "code",
        "id": "I38qmZLhpM2F",
        "outputId": "9ab231ff-c34e-450f-9d3a-8ef2b8068096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-51.3099]) tensor([126.1464])\n"
          ]
        }
      ],
      "source": [
        "print(w.grad, b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WfDV6saTq8XA"
      },
      "source": [
        "##  loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "colab_type": "code",
        "id": "ivmJgJQTpN79",
        "outputId": "831ec258-0f1e-4dbb-843f-d413a54c0784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 1.0\n",
            "1.5782634019851685 -0.21871495246887207\n",
            "2.1210508346557617 -0.8477856516838074\n",
            "2.653946876525879 -1.2839107513427734\n",
            "2.8102939128875732 -1.5840167999267578\n",
            "2.852811574935913 -1.7429653406143188\n",
            "2.925963878631592 -1.843009352684021\n",
            "2.930065155029297 -1.8984636068344116\n",
            "2.959040880203247 -1.941817045211792\n",
            "2.9651601314544678 -1.957231879234314\n",
            "2.980543851852417 -1.9792405366897583\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "print(w.item(), b.item())\n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "  x = torch.randn([20, 1])\n",
        "  y = 3*x - 2\n",
        "  \n",
        "  y_hat = w*x + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(w.item(), b.item())\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vyOqrZZiuLkl"
      },
      "source": [
        "## large problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "qq3Iykk1rMfh",
        "outputId": "cd799469-ac56-4328-aa9e-33e0c17e57c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 58 s\n",
            "Wall time: 14.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "learning_rate = 0.001\n",
        "N = 10000000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True)\n",
        "b = torch.ones([1], requires_grad=True)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  x = torch.randn([N])\n",
        "  y = torch.dot(3*torch.ones([N]), x) - 2\n",
        "  \n",
        "  y_hat = torch.dot(w, x) + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "owaeEn4A01zF",
        "outputId": "1dba52f0-f0de-41b8-8325-ab1e1a6e21b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 58.5 s\n",
            "Wall time: 15.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "learning_rate = 0.001\n",
        "N = 10000000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True, device='cpu')\n",
        "b = torch.ones([1], requires_grad=True, device='cpu')\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  x = torch.randn([N], device='cpu')\n",
        "  y = torch.dot(3*torch.ones([N], device='cpu'), x) - 2\n",
        "  \n",
        "  y_hat = torch.dot(w, x) + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4TmBA3VO9Jva"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0420_PytorchIntro.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
