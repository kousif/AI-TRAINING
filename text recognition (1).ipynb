{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyrbpJl+/X5mBy0lO1f/qe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!ls /content/drive/MyDrive/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKOT6vKPSv-b","executionInfo":{"status":"ok","timestamp":1761277056447,"user_tz":-330,"elapsed":62,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"93cb4a3d-2dc7-4b09-bd1e-f356df73a1d8"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["'capstone test.ipynb'   seq2seq_project  'train (2).zip'   valid_data\n","'Colab Notebooks'      'test (2).zip'\t  train_data\n","'recognition (2).zip'   test_data\t 'valid (2).zip'\n"]}]},{"cell_type":"code","source":["import zipfile\n","\n","zip_path = '/content/drive/MyDrive/recognition (2).zip'\n","output_dir = '/content/dataset'\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(output_dir)\n","\n","# Check that files have been extracted correctly\n","!ls /content/dataset\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn4JHJjOS0Bd","executionInfo":{"status":"ok","timestamp":1761277241423,"user_tz":-330,"elapsed":22980,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"99b2debe-eaea-431d-b908-4d6ce01d480b"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["recognition.zip\n"]}]},{"cell_type":"code","source":["import zipfile\n","\n","inner_zip_path = '/content/dataset/recognition.zip'\n","final_output_dir = '/content/dataset/final'\n","\n","with zipfile.ZipFile(inner_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(final_output_dir)\n","\n","# Confirm extraction\n","!ls /content/dataset/final\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JO23sodxTxSa","executionInfo":{"status":"ok","timestamp":1761277352637,"user_tz":-330,"elapsed":28581,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"5a0775c0-8479-44da-b7a4-23805d92e163"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["recognition\n"]}]},{"cell_type":"code","source":["!ls /content/dataset/final\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYQiPFGtTxNk","executionInfo":{"status":"ok","timestamp":1761277647937,"user_tz":-330,"elapsed":211,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"bba42a0d-890b-470c-e77b-a2ceef785ac5"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["recognition\n"]}]},{"cell_type":"code","source":["!ls /content/dataset/final/recognition\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_wTGtM_VZCX","executionInfo":{"status":"ok","timestamp":1761277790081,"user_tz":-330,"elapsed":102,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"10657073-5617-4e84-8a19-c6f74e78a73c"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["test  test.csv\ttrain  train.csv\n"]}]},{"cell_type":"markdown","source":["# load and prep data"],"metadata":{"id":"YODZVX28WAkZ"}},{"cell_type":"code","source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","\n","# Your special characters for Hindi (use your own if you want)\n","vocab = {'<PAD>':0, '<SOS>':1, '<EOS>':2}\n","characters = \"अआइईउऊऋएऐओऔकखगघचछजझटठडढतथदधनपफबभमयरलवशषसह\"\n","for i, ch in enumerate(characters, 3):\n","    vocab[ch] = i\n","\n","transform = transforms.Compose([\n","    transforms.Resize((128, 512)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","])\n","\n","class HindiTextDataset(Dataset):\n","    def __init__(self, csv_file, vocab, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.vocab = vocab\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def text_to_indices(self, text):\n","        return [self.vocab['<SOS>']] + [self.vocab.get(c, 0) for c in text] + [self.vocab['<EOS>']]\n","\n","    def __getitem__(self, idx):\n","        # Use the \"Filepath\" column in your CSV for image filename\n","        img_path = f\"/content/dataset/final/recognition/{self.data.iloc[idx]['Filepath']}\"\n","        img = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        # Use the \"Text\" column in your CSV for labels\n","        text = self.text_to_indices(self.data.iloc[idx]['Text'])\n","        return img, torch.tensor(text)\n","\n","def collate_fn(batch):\n","    imgs, texts = zip(*batch)\n","    imgs = torch.stack(imgs)\n","    lengths = [len(t) for t in texts]\n","    max_len = max(lengths)\n","    padded_texts = torch.zeros(len(texts), max_len, dtype=torch.long)\n","    for i, t in enumerate(texts):\n","        padded_texts[i, :lengths[i]] = t\n","    return imgs, padded_texts, lengths\n","\n","train_csv = '/content/dataset/final/recognition/train.csv'\n","train_dataset = HindiTextDataset(train_csv, vocab, transform)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n"],"metadata":{"id":"LGoWGKicYWNs","executionInfo":{"status":"ok","timestamp":1761278559430,"user_tz":-330,"elapsed":242,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["# Model Definition (CNN Encoder + Attention LSTM Decoder)"],"metadata":{"id":"efmMB-4FWWnN"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNNEncoder(nn.Module):\n","    def __init__(self, output_dim=128):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n","            nn.MaxPool2d(2,2)\n","        )\n","        self.output_dim = output_dim\n","    def forward(self, x):\n","        features = self.conv(x)\n","        b, c, h, w = features.size()\n","        features = features.permute(0,3,1,2).contiguous().view(b, w, -1)\n","        return features\n","\n","class Attention(nn.Module):\n","    def __init__(self, enc_dim, dec_dim):\n","        super().__init__()\n","        self.attn = nn.Linear(enc_dim + dec_dim, dec_dim)\n","        self.v = nn.Parameter(torch.rand(dec_dim))\n","    def forward(self, encoder_outputs, hidden):\n","        batch_size = encoder_outputs.size(0)\n","        src_len = encoder_outputs.size(1)\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n","        energy = energy.permute(0, 2, 1)\n","        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n","        attention = torch.bmm(v, energy).squeeze(1)\n","        return F.softmax(attention, dim=1)\n","\n","class DecoderLSTM(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, enc_dim, dec_dim):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim + enc_dim, dec_dim, batch_first=True)\n","        self.attention = Attention(enc_dim, dec_dim)\n","        self.fc_out = nn.Linear(dec_dim, vocab_size)\n","    def forward(self, input_token, hidden, cell, encoder_output):\n","        embedded = self.embedding(input_token).unsqueeze(1)\n","        attn_weights = self.attention(encoder_output, hidden.squeeze(0)).unsqueeze(1)\n","        context = torch.bmm(attn_weights, encoder_output)\n","        lstm_input = torch.cat((embedded, context), dim=2)\n","        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n","        prediction = self.fc_out(output.squeeze(1))\n","        return prediction, hidden, cell, attn_weights\n"],"metadata":{"id":"09-scyaFWY0B","executionInfo":{"status":"ok","timestamp":1761278563452,"user_tz":-330,"elapsed":28,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}}},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":["# Traning Loop"],"metadata":{"id":"ohbVYyIzWlQ1"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('/content/dataset/final/recognition/train.csv')\n","print(df.columns)\n","print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsYHTP2YXOGG","executionInfo":{"status":"ok","timestamp":1761278569801,"user_tz":-330,"elapsed":158,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"ce3358df-e05f-463a-e12b-ec80991c292a"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Filepath', 'Text', 'Language'], dtype='object')\n","                             Filepath       Text Language\n","0    train/english/A_image_1005_0.jpg   CULTURAL  english\n","1    train/english/A_image_1005_1.jpg  JAGANNATH  english\n","2   train/english/A_image_1005_10.jpg     Daily)  english\n","3  train/english/A_image_1005_100.jpg        the  english\n","4  train/english/A_image_1005_101.jpg     Temple  english\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Subset\n","\n","# Use only the first 6 samples\n","small_dataset = Subset(train_dataset, range(6))\n","train_loader = DataLoader(small_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","encoder = CNNEncoder().to(device)\n","decoder = DecoderLSTM(len(vocab), 128, 128*32, 256).to(device)\n","\n","optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n","\n","for epoch in range(1):  # Run for only 1 epoch (quick test)\n","    encoder.train()\n","    decoder.train()\n","    for imgs, texts, lengths in train_loader:\n","        imgs = imgs.to(device)\n","        texts = texts.to(device)\n","        optimizer.zero_grad()\n","        encoder_outputs = encoder(imgs)\n","        hidden = torch.zeros(1, imgs.size(0), 256).to(device)\n","        cell = torch.zeros(1, imgs.size(0), 256).to(device)\n","        input_token = texts[:, 0]\n","        loss = 0\n","        max_len = texts.size(1)\n","        for t in range(1, max_len):\n","            output, hidden, cell, _ = decoder(input_token, hidden, cell, encoder_outputs)\n","            loss += criterion(output, texts[:, t])\n","            input_token = texts[:, t]\n","        loss.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1}, Loss {loss.item()/max_len}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RkO2bwsd0M8","executionInfo":{"status":"ok","timestamp":1761279970393,"user_tz":-330,"elapsed":10807,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"0f701bae-809c-42f9-850e-d05eec9b81d5"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss nan\n"]}]},{"cell_type":"markdown","source":["# interference"],"metadata":{"id":"zU4U3Nl7eoxl"}},{"cell_type":"code","source":["def predict_image(image_path, encoder, decoder, vocab, max_len=30):\n","    # Prepare image\n","    img = Image.open(image_path).convert('RGB')\n","    img = transform(img).unsqueeze(0).to(device)\n","\n","    # Inverse vocab for index to char\n","    inv_vocab = {v: k for k, v in vocab.items()}\n","\n","    # Encoder forward\n","    encoder.eval()\n","    decoder.eval()\n","    with torch.no_grad():\n","        encoder_outputs = encoder(img)\n","        hidden = torch.zeros(1, 1, 256).to(device)\n","        cell = torch.zeros(1, 1, 256).to(device)\n","\n","        input_token = torch.tensor([vocab['<SOS>']], device=device)\n","        predicted_indices = []\n","        for _ in range(max_len):\n","            output, hidden, cell, _ = decoder(input_token, hidden, cell, encoder_outputs)\n","            top1 = output.argmax(1)\n","            if top1.item() == vocab['<EOS>']:\n","                break\n","            predicted_indices.append(top1.item())\n","            input_token = top1\n","\n","    predicted_text = ''.join([inv_vocab[idx] for idx in predicted_indices if idx in inv_vocab])\n","    return predicted_text\n"],"metadata":{"id":"Km-FXiRkel_B","executionInfo":{"status":"ok","timestamp":1761280206834,"user_tz":-330,"elapsed":45,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load test CSV (update path if necessary)\n","test_df = pd.read_csv('/content/dataset/final/recognition/test.csv')\n","\n","for idx in range(5):  # Predict for first 5 test images\n","    image_path = '/content/dataset/final/recognition/' + test_df.iloc[idx]['Filepath']\n","    actual_text = test_df.iloc[idx]['Text']\n","    predicted_text = predict_image(image_path, encoder, decoder, vocab)\n","    print(f\"Test Sample {idx+1}\")\n","    print(\"Actual Text:\", actual_text)\n","    print(\"Predicted Text:\", predicted_text)\n","    print(\"-\"*40)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTtEvZPUfQkN","executionInfo":{"status":"ok","timestamp":1761280338701,"user_tz":-330,"elapsed":696,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"df4eb098-8ff4-42d9-d81a-9e2b02b9342b"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Sample 1\n","Actual Text: JUBILEE\n","Predicted Text: \n","----------------------------------------\n","Test Sample 2\n","Actual Text: FUNCTION\n","Predicted Text: \n","----------------------------------------\n","Test Sample 3\n","Actual Text: OF\n","Predicted Text: \n","----------------------------------------\n","Test Sample 4\n","Actual Text: জয়ন্তী\n","Predicted Text: \n","----------------------------------------\n","Test Sample 5\n","Actual Text: 20\n","Predicted Text: \n","----------------------------------------\n"]}]},{"cell_type":"code","source":["idx = 1  # Choose row number\n","image_path = '/content/dataset/final/recognition/' + test_df.iloc[idx]['Filepath']\n","actual_text = test_df.iloc[idx]['Text']\n","predicted_text = predict_image(image_path, encoder, decoder, vocab)\n","print(\"Actual Text:\", actual_text)\n","print(\"Predicted Text:\", predicted_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0yIX-HSfvc8","executionInfo":{"status":"ok","timestamp":1761280490346,"user_tz":-330,"elapsed":129,"user":{"displayName":"Shaikkousif San","userId":"04938205231385929823"}},"outputId":"94d04c64-6d2f-4242-81d5-1e45fe533962"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Actual Text: FUNCTION\n","Predicted Text: \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JsQUuVWNf094"},"execution_count":null,"outputs":[]}]}